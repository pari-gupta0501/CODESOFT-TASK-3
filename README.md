# CODESOFT-TASK-3

---

# ğŸ“¸ Image Captioning using Deep Learning

## ğŸ§  Project Objective

To build an AI model that automatically generates descriptive captions for input images using a combination of CNN (InceptionV3) and RNN (LSTM) architectures.

---

## ğŸš€ Technologies Used

Python

TensorFlow / Keras

NumPy, Matplotlib

Pre-trained InceptionV3 (for feature extraction)

LSTM (for sequence modeling)

---

## ğŸ“ Dataset

You can use:

Flickr8k or Flickr30k

OR a custom dataset with image_path -> captions format

---

## ğŸ”§ How It Works

Feature Extraction: Images are processed using InceptionV3 to extract deep features.

Text Preprocessing: Captions are cleaned, tokenized, and padded.

Model Training: LSTM is trained on image features + captions.

Caption Generation: New captions are generated using a greedy approach.

---

## ğŸ› ï¸ File Structure

image-captioning/

â”œâ”€â”€ images/              # Image dataset

â”œâ”€â”€ captions.txt         # Captions for each image

â”œâ”€â”€ model.py             # CNN + RNN model

â”œâ”€â”€ train.py             # Model training code

â”œâ”€â”€ app.py               # Caption generation script

â”œâ”€â”€ utils.py             # Helper functions

â””â”€â”€ README.md            # Project documentation

---

## âœ… Steps to Run

1. Install Dependencies
```
pip install tensorflow keras numpy matplotlib pillow
```
2. Extract Image Features
```
### Inside utils.py

features = extract_features('images/example.jpg')
```
3. Clean Captions and Tokenize
```
cleaned = clean_caption("A boy playing with a dog")
```
4. Train Model
```
python train.py
```
5. Generate Caption
```
python app.py

### Output: "A boy is playing with a ball"
```
---

## SAMPLE OUTPUT

<img width="468" height="414" alt="image" src="https://github.com/user-attachments/assets/18322aed-6725-4215-b680-7c2c9764aaa6" />


## ğŸ“Œ Future Improvements

Use Beam Search instead of Greedy Search

Use Attention Mechanisms

Deploy as a Web App

---
